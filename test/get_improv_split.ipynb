{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/z/tavernor/code/ModelingIndividualEvaluators/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from SERDatasets import ImprovDatasetConstructor\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "data = ImprovDatasetConstructor(dataset_save_location='../prepared_datasets/improv_dataset.pk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "speaker_to_annotators = {f'{g}0{i}': [] for g in ['M', 'F'] for i in range(1,7)}\n",
    "speaker_to_datasize = {f'{g}0{i}': 0 for g in ['M', 'F'] for i in range(1,7)}\n",
    "for utt_id in data.labels:\n",
    "    annotators = data.labels[utt_id]['annotators']\n",
    "    match = re.search(r'-([FM]0[1-6])-', utt_id)\n",
    "    speaker_to_annotators[match.group(0).replace('-','')].extend(annotators)\n",
    "    speaker_to_datasize[match.group(0).replace('-','')] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_to_annotators = {x: set(speaker_to_annotators[x]) for x in speaker_to_annotators}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'c3rguqctj3qv57avvd1auph3g3-p3b': {'M01'},\n",
       " 'p2ej6pr8f950rulpdkrqea4db0-p3b': {'F06'},\n",
       " '3bgvfacsgsv5khlph0vrg30d63-p3b': {'F02'},\n",
       " 'e77a0ejejogqba4eoo9evci6b6-p3b': {'F05'},\n",
       " '6dq25lmn3tpsi59p858c673u46-p3b': {'F02'},\n",
       " '17qnfnhcn28ep46hidcfoftu52-p3b': {'F06'},\n",
       " 'quhtr8erbtdq8uk8neu4ahbjk4-p3b': {'M01'},\n",
       " 'A3KBQJ36JL7G7C-p1': {'M03'},\n",
       " 'mdth1cd9c7534ld062tkhpkch2-p3b': {'F01'},\n",
       " 'qgvtj408e2mlis9qbcolldr3a6-p3b': {'F03'},\n",
       " '54pqi818compujpopuqos7ql21-p3a': {'F05'},\n",
       " 'l86bd511okn032pitt5j30ert5-p2': {'F03'},\n",
       " 'jtdie0b8b5thslb9lecebf4dv6-p3b': {'M05'},\n",
       " 'AAE9H4ZIKQS37-p1': {'M05'},\n",
       " 'k00rpsnvq46626i5erckirdeq7-p3b': {'F01'},\n",
       " 'ev7mo9kkj8bu6lfbdmd0b7vot1-p3a': {'F01'},\n",
       " 'n8d09c9g0dk3ol976v91i9n4i5-p3a': {'F04'},\n",
       " 'l0oehm30h1ebfgi2675pscrpn0-p2': {'M01'},\n",
       " 'cc5dkr7ovud56jkedobb7d4480-p2': {'M01'},\n",
       " 'A2AMH6PII3Z5JA-p1': {'F02'},\n",
       " 'A7K79O7QPK86A-p_spon': {'F05'},\n",
       " '62fjv2tr1s1fpbu5lak5vuhea2-p3b': {'M03'},\n",
       " 'kepht27gr2gbnd51co93fm0dv2-p3b': {'M03'},\n",
       " 'A3DE3ZWIPQO5BG-p1': {'F01'},\n",
       " 'A2WHA7XE143S4T-p1': {'F04'},\n",
       " 'pctgvbhmlb9q30tpfkkgvjjul1-p3b': {'M05'},\n",
       " 'i3oduhpbi7of5jom4jr7san216-p3b': {'F06'},\n",
       " 'A12ZU22BL5VIWV-p1': {'M03'},\n",
       " 'A2M7XLRCEXGY9M-p_spon': {'M06'},\n",
       " '54rabtv7fb76e46h7b02vrnmb6-p3b': {'F01'},\n",
       " 'A1JRXVE6CEZWXG-p1': {'F05'},\n",
       " 'g5106r08npfui2tujprgf1t9o5-p3a': {'M01'},\n",
       " 'AHYJONIS0LE1X-p1': {'M03'},\n",
       " 'tau8jfeb1b28uojmt3sfao0lc7-p3b': {'M04'},\n",
       " 'bmiv3ca231k45d9eh4megkl743-p2': {'F02'},\n",
       " 'ee2scqqmuh8upf9756op3odf61-p3a': {'F02'},\n",
       " 'o34l4rret5ktr5e5p7egtu8715-p3a': {'F02'},\n",
       " 'A4A7138ME4YG3-p_spon': {'F05'},\n",
       " 'A2ZD4Z5V37EJOP-p1': {'M02'},\n",
       " 'bsi5v8ntpbdi3s6ki059i4tpr4-p3a': {'F05'},\n",
       " 'A2LNYREG3PWB02-p1': {'M05'},\n",
       " 'nm1ulv825qmski799tup1s9gb6-p3b': {'F06'},\n",
       " '2qud4qmcoso13iqm78ngd9p4v4-p3b': {'M03'},\n",
       " 'g2u1pi9uvr8cpuihmo5nrqh7j2-p3b': {'M03'},\n",
       " 'A3CWGT3EMQ17Y0-p1': {'M03'},\n",
       " 'AIQ1I6ODSIO56-p1': {'M04'},\n",
       " 'A2115WEI1GCBLY-p1': {'M02'},\n",
       " 'A2AVFNOKFHQ2ME-p1': {'M06'},\n",
       " 'tlj0e95pq5lugareb7cpos3047-p3a': {'M03'},\n",
       " 'A2WLBR9LYCTC12-p1': {'M04'},\n",
       " 'A1NM7ZPZ3NH412-p_spon': {'M01'},\n",
       " 'utpt7bpa5rsma9cqkbepq23md0-p3b': {'M03'},\n",
       " 'A3IWXMVBLBBBVM-p_spon': {'F03'},\n",
       " '9jkmkvb3he2hasq7ue12o6m0t2-p3b': {'F06'},\n",
       " 'tmkhakfl4a7dp9f1qdoivrprh3-p3b': {'F06'},\n",
       " 'A2VRQML8Q3XYP4-p1': {'M01'},\n",
       " 'hv68io1rni7ad4chq501mqbe23-p3a': {'M03'},\n",
       " '8islsfiq67k7in3mpfnmoic0v2-p3b': {'F06'},\n",
       " '4o3btud7h4d8b5cbrmfojb1cp4-p3b': {'F06'},\n",
       " 'q3nfl2u300g6h1pord5jd98355-p3a': {'M06'},\n",
       " '0jcg16bd6rrn160nqcjmvs9m60-p3a': {'F01'},\n",
       " 'utfdif26f8rcdo4s89uh9q6iv2-p3b': {'F05'},\n",
       " 'b3f1q9pv5tkgirb7tnj0qif1b6-p3b': {'M01'},\n",
       " 'rom3t28oekqnhn8fglh8j88292-p3a': {'M01'},\n",
       " 'A3OU5LFAUPH1EE-p_spon': {'M04'},\n",
       " 'AHXWX666GANH1-p1': {'F02'},\n",
       " 'A200MPSU1OKLIZ-p1': {'F06'},\n",
       " 'A1TZUPNN3DHSDD-p1': {'F02'},\n",
       " 'ch0v9cj4g8q3057fgunm5j7mo0-p3b': {'F05'},\n",
       " 'gole4mbvb8rcoobqj75s81amb0-p2': {'F05'},\n",
       " '0tjote8tfh8ts2jota3t2u2jf0-p3a': {'F05'},\n",
       " 'kq5froe7kvpbbgf8902g0m59i2-p3a': {'F05'},\n",
       " '8u6t0k2jjcuhq8uqrpcm0k1nu4-p3b': {'F06'},\n",
       " '78bd2jm0so6mn3hakno816ai17-p3b': {'M05'},\n",
       " 'ADKDC0IXTYCIJ-p_spon': {'F01'},\n",
       " 'A28ZFH94QVZM2F-p_spon': {'F03'},\n",
       " 'A1FC4ZLFOKK2B9-p1': {'M03'},\n",
       " '71j0dp1uji16cff2v3gg41dph2-p3a': {'M05'},\n",
       " 'm7t5l53komvqchami7pj3g5fm5-p2': {'F01'},\n",
       " '3a695d6ka9hgapdhfq33svkmq1-p3a': {'F01'},\n",
       " 'frvaepu2cddhvvrp7bgeq614g3-p3b': {'F02'},\n",
       " 'A4IADV03FHSQY-p_spon': {'F03'},\n",
       " 'AGYZ0GAAUIJZX-p_spon': {'F03'},\n",
       " '2jrqfn8pkq41sft04hgdunb4g5-p3b': {'M01'},\n",
       " 'A1GD3MQELM1R9M-p_spon': {'M03'},\n",
       " '06ek20msqgjcb9ol54rvr000c0-p3b': {'M03'},\n",
       " 'rvji4hig8ios28rpsagjhn75f7-p3a': {'M06'},\n",
       " 'gmqhlkvukscu9pcg1usgnalaj0-p3b': {'F04'},\n",
       " 'f2eg9k6omr8o1u8cnf0kdl5rk6-p3b': {'F04'},\n",
       " 'c14ih40r7do4ch2i5nno0fdlm2-p3b': {'F05'},\n",
       " 'jcut7mrfli1couc0b328pg4vu3-p3b': {'M03'},\n",
       " '7g74i9q5vc81oull5tafh5b990-p3b': {'M05'},\n",
       " 'A1DXW000R40B2N-p_spon': {'M03'},\n",
       " 'k8rbvnatn75tto2nrgbb6p5i26-p3b': {'M05'},\n",
       " 'AIUKV0KVALMY6-p_spon': {'M05'},\n",
       " 'souvu5jot460vj7hbkm5uc4u10-p3b': {'F02'},\n",
       " 'A2VJCYBTO30QKS-p1': {'M05'},\n",
       " '6t46htuc29srp0efh2u2c9b3a2-p3b': {'M06'},\n",
       " 'ALBYKYLJW4501-p1': {'F03'},\n",
       " 'bv006kb0ppk00s6ussth9v9ov6-p3b': {'F05'},\n",
       " 'A33104K1JTM9I3-p1': {'F06'},\n",
       " 'AAH21GM03ND5R-p_spon': {'M02'},\n",
       " 'A2JS05RUC1CUTL-p_spon': {'M02'},\n",
       " 'A34EYPUZ3B5RI3-p_spon': {'M03'},\n",
       " 'A16TBEOPV8V1QZ-p_spon': {'M06'},\n",
       " 'A1K9WP8Q74E9G2-p_spon': {'F03'},\n",
       " 'A30HAYH08Q3YR2-p_spon': {'F03'},\n",
       " 'AJE2GXXF7UMBN-p1': {'F03'},\n",
       " 'A249HL67FLOSI1-p_spon': {'F04'},\n",
       " 'A1CWN0MWHQ1QYN-p1': {'F04'},\n",
       " 'AEOR2IMPH8C2A-p1': {'F06'},\n",
       " 'doc2bklad1t67kosuk1hso4dl5-p3b': {'M01'},\n",
       " 'A9JHTV37LSE5F-p1': {'F01'},\n",
       " 'A3LXRZZ3GV0LRD-p1': {'F04'},\n",
       " 'A37K9AREXG3P5P-p1': {'F04'},\n",
       " 't51mtug6oo69r37t4s2c9cc305-p3b': {'F05'},\n",
       " 'hm2b2detrik362memaogt916t2-p3b': {'M05'},\n",
       " 'AOCXB5MBZZ09Z-p1': {'F01'},\n",
       " 'A1BPHW0KCTG34P-p_spon': {'F03'},\n",
       " 'fcc9olqndj4coc44j1afjcpq44-p3b': {'M03'},\n",
       " 'ASSDGKLK7DWH4-p1': {'F01'},\n",
       " 'AD8URUKU1POQZ-p1': {'F01'},\n",
       " 'A12EJJ5CPWXD01-p1': {'F01'},\n",
       " '7uss8nb28302k8kelugnbcckr2-p3a': {'F01'},\n",
       " 'A1FLUOSTITG97W-p1': {'F02'},\n",
       " 'A6OBPKNDYT2EM-p1': {'M02'},\n",
       " 'A34Q4UR41F2HD2-p1': {'M03'},\n",
       " 'A2BX9RY192YG6A-p1': {'M04'},\n",
       " '6p9r0k2vl5c83brgrcdjtjlh32-p3b': {'F02'},\n",
       " 'AZFMTIDXO292D-p_spon': {'F02'},\n",
       " 'qsl8labej0k0lqn1jmr7hhju80-p3b': {'M05'},\n",
       " 'tah074b33d88rofbdc3t619ng0-p3a': {'F05'},\n",
       " 'fks3ae96i9n76m56qvu0bvk3p5-p3b': {'M02'},\n",
       " 'A1J6I5HGBSAAVL-p1': {'M06'},\n",
       " 'l5u8g2t8f5b9r1b2i1dffqakk1-p3b': {'M06'},\n",
       " 't1te1fut41r7fd5jh0t9scgi47-p3b': {'M05'},\n",
       " 'k613gmf41gjj5npgchfmmun1m1-p3a': {'F04'},\n",
       " 'A2J2FZ0IGJSZ1Z-p1': {'F05'},\n",
       " 'A2KXCRDOR6UHEG-p1': {'F04'},\n",
       " 'd5l5ougfarbbg5qjc92ickh0l7-p3b': {'M05'},\n",
       " 'A32I9KI0Y5STBJ-p1': {'F06'},\n",
       " 'A2KEBWYF9H5U35-p1': {'F06'},\n",
       " 'A3REL9J7HR6151-p_spon': {'M06'},\n",
       " 'A37Q1Y4ZV3YD89-p1': {'F04'},\n",
       " 'AMSD0JV1W7V9F-p1': {'F05'},\n",
       " 'a7jo21gtjkacdsl7lj2p0bifv7-p3a': {'M04'},\n",
       " '06h2vk5s4ssehu44sjbgllu223-p3b': {'M05'},\n",
       " 'AV3IHCR638T4B-p_spon': {'F02'},\n",
       " 'AE298K1SUDSPK-p1': {'F06'},\n",
       " 'A10RNK847NK97J-p1': {'F06'},\n",
       " 'A1MJJI1R6P90K7-p_spon': {'F06'},\n",
       " 'cc4sajvokk7u082m5gvl23nk53-p3b': {'F02'},\n",
       " 'gua6q90ig452c48d4j7vb1a3b4-p3b': {'F02'},\n",
       " 'AY722EQ0H1UQS-p1': {'F02'},\n",
       " 'A3TEAFANIBVPAF-p_spon': {'F06'},\n",
       " 'rqvtll1ep77ukecmcd3heov4a1-p2': {'M02'},\n",
       " 'A1BLJZMHHWHT4Y-p_spon': {'F02'},\n",
       " '828abrjc1op1j01niikbnhohm4-p3a': {'F04'}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "annotator_to_speaker = {}\n",
    "for annotator in data.individual_annotators:\n",
    "    annotator_to_speaker[annotator] = []\n",
    "    for utt_id in data.individual_annotators[annotator]:\n",
    "        match = re.search(r'-([FM]0[1-6])-', utt_id)\n",
    "        annotator_to_speaker[annotator].append(match.group(0).replace('-',''))\n",
    "    annotator_to_speaker[annotator] = set(annotator_to_speaker[annotator])\n",
    "    \n",
    "ignored_annotators = {i: v for i,v in annotator_to_speaker.items() if len(v) == 1}\n",
    "ignored_annotators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 3/12 [00:00<00:02,  4.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given ['F05', 'M04'] best choice leaves 5 annotators uncovered and covers 1434. Train split size: 69.34%. Validation/Test split: ((['F04', 'M05'], ['M01', 'F02']), (1300, 1287), set())\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 7/12 [00:01<00:01,  4.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given ['F05', 'M05'] best choice leaves 5 annotators uncovered and covers 1430. Train split size: 68.48%. Validation/Test split: ((['M03', 'F04'], ['M01', 'F02']), (1373, 1287), set())\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 8/12 [00:02<00:01,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given ['F05', 'M03'] best choice leaves 5 annotators uncovered and covers 1434. Train split size: 69.34%. Validation/Test split: ((['F04', 'M05'], ['M01', 'F02']), (1300, 1287), set())\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 9/12 [00:02<00:01,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given ['F05', 'M06'] best choice leaves 5 annotators uncovered and covers 1434. Train split size: 69.34%. Validation/Test split: ((['F04', 'M05'], ['M01', 'F02']), (1300, 1287), set())\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:03<00:00,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given ['F05', 'M02'] best choice leaves 5 annotators uncovered and covers 1434. Train split size: 69.34%. Validation/Test split: ((['F04', 'M05'], ['M01', 'F02']), (1300, 1287), set())\n",
      "Given ['F05'] best choice leaves 5 annotators uncovered and covers 1434. Train split size: 69.34%. Validation/Test split: ((['F04', 'M05'], ['M01', 'F02']), (1300, 1287), set())\n",
      "--- res\n",
      "(['F05', 'M04', 'F03', 'M02', 'F01', 'M06', 'F06', 'M03'], {'5gcbrspms2hdl9do2n528pfal5-p3b', 'A36L397WEN8VRN-p_spon', '7s9qdc35a9mfoedulqepo1bip6-p3b', 'A1RWNYJA5X25YH-p1', 'qrbki0m9qs4p788ipamfb1r254-p3a'}, 5851, ((['F04', 'M05'], ['M01', 'F02']), (1300, 1287), set()))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "# Do this recursively to select best split \n",
    "def get_annotators(selected_speakers, uncovered_annotators, selected_datasize, depth=0, check_test_set=False):\n",
    "    can_valid_test_set_be_found = set(speaker_to_annotators.keys()) - set(selected_speakers)\n",
    "    if check_test_set:\n",
    "        can_valid_test_set_be_found = select_val_test_split(can_valid_test_set_be_found)\n",
    "\n",
    "    # Base case -- selected more than 60% of dataset set\n",
    "    if selected_datasize/len(data.labels) > 0.7:\n",
    "        return False\n",
    "        return selected_speakers, uncovered_annotators, selected_datasize\n",
    "\n",
    "    if not can_valid_test_set_be_found:\n",
    "        return False\n",
    "\n",
    "    # Base case -- no covered annotators\n",
    "    if not len(uncovered_annotators):\n",
    "        return selected_speakers, uncovered_annotators, selected_datasize, can_valid_test_set_be_found\n",
    "\n",
    "    # Base case -- selected all speakers\n",
    "    if len(selected_speakers) == len(speaker_to_annotators):\n",
    "        return selected_speakers, uncovered_annotators, selected_datasize, can_valid_test_set_be_found\n",
    "\n",
    "    # Recursive case -- score all speakers and return speakers that cover the most annotators\n",
    "    best_score = range(99999)\n",
    "    best_speakers = None\n",
    "    best_size = None\n",
    "    best_test_set = None\n",
    "    choices = list(speaker_to_annotators.keys())\n",
    "    random.shuffle(choices)\n",
    "    loop_value = tqdm(choices) if depth < 1 else choices\n",
    "    last_chosen = selected_speakers[-1] if len(selected_speakers) else ''\n",
    "    for speaker in loop_value:\n",
    "        if speaker in selected_speakers + ['M01', 'F02']:\n",
    "            continue\n",
    "        if ('M' in speaker and 'M' in last_chosen) or ('F' in speaker and 'F' in last_chosen):\n",
    "            continue # Alternate between choosing a male and female speaker to ensure gender balance in train/val/test\n",
    "        res = get_annotators(selected_speakers + [speaker], uncovered_annotators - speaker_to_annotators[speaker], selected_datasize + speaker_to_datasize[speaker], depth+1, check_test_set=check_test_set)\n",
    "        if res:\n",
    "            possible_speakers, possible_score, possible_size, valid_test_set = res\n",
    "        else:\n",
    "            continue # If get_annotators returns false then too much data was selected \n",
    "        if not valid_test_set:\n",
    "            continue\n",
    "        if len(possible_score) < len(best_score) or (len(possible_score) == len(best_score) and possible_size > best_size):\n",
    "            best_speakers = possible_speakers\n",
    "            best_score = possible_score\n",
    "            best_size = possible_size\n",
    "            best_test_set = valid_test_set\n",
    "    if best_speakers is None:\n",
    "        best_speakers = selected_speakers\n",
    "        best_size = selected_datasize\n",
    "        best_score = uncovered_annotators\n",
    "        best_test_set = can_valid_test_set_be_found\n",
    "    if depth < 2: # Only print this for the parent and sub-parent\n",
    "        covered_annotators = set.union(*[speaker_to_annotators[speaker] for speaker in best_speakers])\n",
    "        print('Given', selected_speakers, f'best choice leaves {len(best_score)} annotators uncovered and covers {len(covered_annotators)}. Train split size: {100*best_size/len(data.labels):.2f}%. Validation/Test split: {best_test_set}')\n",
    "    return best_speakers, best_score, best_size, best_test_set\n",
    "\n",
    "def select_val_test_split(possible_speakers, selected_speakers=([],[]), datasizes=(0,0)):\n",
    "    val_speakers, test_speakers = selected_speakers\n",
    "    val_size, test_size = datasizes\n",
    "    val_last_chosen = val_speakers[-1] if len(val_speakers) else ''\n",
    "    test_last_chosen = test_speakers[-1] if len(test_speakers) else ''\n",
    "    # Base case -- no speaker \n",
    "    if not len(possible_speakers):\n",
    "        # If datasizes are not balanced well enough this should fail\n",
    "        if val_size/len(data.labels) < 0.15 or test_size/len(data.labels) < 0.15:\n",
    "            return False\n",
    "\n",
    "        return selected_speakers, datasizes, possible_speakers\n",
    "    # Base case -- exactly one speaker remaining\n",
    "    if len(possible_speakers) == 1:\n",
    "        if val_size/len(data.labels) < 0.15 and test_size/len(data.labels) < 0.15:\n",
    "            return False\n",
    "\n",
    "        if val_size/len(data.labels) < 0.15:\n",
    "            # Val size is too small, if we can add possible speaker to bring it up then we can continue otherwise fail here\n",
    "            new_size = val_size + speaker_to_datasize[next(iter(possible_speakers))]\n",
    "            if new_size/len(data.labels) < 0.15:\n",
    "                return False\n",
    "        if test_size/len(data.labels) < 0.15:\n",
    "            # Val size is too small, if we can add possible speaker to bring it up then we can continue otherwise fail here\n",
    "            new_size = test_size + speaker_to_datasize[next(iter(possible_speakers))]\n",
    "            if new_size/len(data.labels) < 0.15:\n",
    "                return False\n",
    "        return selected_speakers, datasizes, possible_speakers\n",
    "\n",
    "    best_res = None\n",
    "    min_dist = 9999\n",
    "    for val_speaker in possible_speakers:\n",
    "        if val_speaker in val_speakers:\n",
    "            continue\n",
    "        if ('M' in val_speaker and 'M' in val_last_chosen) or ('F' in val_speaker and 'F' in val_last_chosen):\n",
    "            continue\n",
    "        for test_speaker in possible_speakers:\n",
    "            if test_speaker == val_speaker:\n",
    "                continue\n",
    "            if test_speaker in test_speakers:\n",
    "                continue\n",
    "            if ('M' in test_speaker and 'M' in test_last_chosen) or ('F' in test_speaker and 'F' in test_last_chosen):\n",
    "                continue # Alternate between choosing a male and female speaker to ensure gender balance in train/val/test\n",
    "            new_possible_speakers = set(possible_speakers) - set([val_speaker, test_speaker])\n",
    "            res = select_val_test_split(new_possible_speakers, (val_speakers + [val_speaker], test_speakers + [test_speaker]), (val_size + speaker_to_datasize[val_speaker], test_size + speaker_to_datasize[test_speaker]))\n",
    "            if res:\n",
    "                sel, sizes, p_spkrs = res\n",
    "                abs_diff = abs(sizes[0]-sizes[1])\n",
    "                if abs_diff < min_dist:\n",
    "                    best_res = res\n",
    "                    min_dist = abs_diff\n",
    "            else:\n",
    "                continue # If get_annotators returns false then too much data was selected\n",
    "    if best_res is not None:\n",
    "        return best_res\n",
    "    # If we get to here then we failed to find a valid test split \n",
    "    return False\n",
    "\n",
    "# We now select speaker such that it covers as much as possible of the remaining speakers \n",
    "selected_speakers = ['F05'] # Select a random initial speaker to build train/test set around\n",
    "uncovered_annotators = set(data.individual_annotators.keys()) - set(ignored_annotators.keys()) - set(speaker_to_annotators['F05'])\n",
    "selected_datasize = speaker_to_datasize['F05']\n",
    "res = get_annotators(selected_speakers, uncovered_annotators, selected_datasize, check_test_set=True)\n",
    "print('--- res')\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final data split: \n",
    "Train: F01,F03,F05,F05,M02,M03,M04,M06\n",
    "Validation: F02,M01\n",
    "Test: F04,M05\n",
    "\n",
    "Doesn't cover 5 annotators shared between at least two speakers, and doesn't cover annotators that only occur to one speaker. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
